{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "Details_and_people_filename = \"Opport per KRA and INDUSTRY Final.xlsx\"\n",
    "\n",
    "#Loading the Details source table\n",
    "Details = pd.read_excel(data_folder_directory + Details_and_people_filename,sheet_name=\"data\")\n",
    "People = pd.read_excel(data_folder_directory + Details_and_people_filename,sheet_name=\"People\")\n",
    "People = People.dropna(how='all')\n",
    "KRA_map = dict(People[['Naam schoon','Service Line']].values)\n",
    "Details['KRA'] = [KRA_map[x] if x in KRA_map else 'not found' for x in Details['Opportunity Leader']]\n",
    "Details['Quarters'] = pd.PeriodIndex(Details['Expected Close Date'], freq='Q')\n",
    "\n",
    "#Making the quarters MIndex column\n",
    "quarters_list = list(set([str(Details['Quarters'][i]) for i in range(len(Details))]))\n",
    "quarters_list = sorted(quarters_list,key=lambda element: (int(element[0:4]), int(element[-1])))\n",
    "quarters_mapping = {}\n",
    "idx = 1\n",
    "for i in quarters_list:\n",
    "    quarters_mapping[i] = idx\n",
    "    idx += 1\n",
    "Details['QuartersMIndex'] = [quarters_mapping[str(Details['Quarters'][i])] for i in range(len(Details))]\n",
    "\n",
    "#Making the probability buckets column\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "Details['Probability buckets'] = pd.cut(Details['Probability (%)'],bins,labels=['0 to 25%', '25% to 50%', '50% to 75%', '75% to 100%'])\n",
    "Details['Probability buckets'] = Details['Probability buckets'].astype(object).fillna(0)\n",
    "#Making the probability buckets MIndex column\n",
    "probability_Mindex = {0:1,'0 to 25%':2,'25% to 50%':3,'50% to 75%':4, '75% to 100%':5} \n",
    "Details['Probability Buckets MIndex'] = [probability_Mindex[Details['Probability buckets'][i]] for i in range(len(Details))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "Employee_filename = \"FTE input file for standard weekly reporting QRT006 - FTE (star) (16-16-42).xlsx\"\n",
    "\n",
    "#Loading the employee source table\n",
    "Employee = pd.read_excel(data_folder_directory + Employee_filename,sheet_name=\"QRT006\")\n",
    "col_start = int(Employee.iloc[6][Employee.iloc[6].str.find(\"Profit Centre Hierarchy Level 4\") == 0].index.to_list()[0].split()[-1])\n",
    "col_end = int(Employee.iloc[6][Employee.iloc[6].str.find(\"YTD FTE\") == 0].index.to_list()[0].split()[-1])\n",
    "Employee = Employee.iloc[6:,col_start:col_end+1]\n",
    "Employee.columns = Employee.iloc[0]\n",
    "Employee = Employee[1:]\n",
    "Employee = Employee.reset_index(drop=True)\n",
    "Employee = Employee[Employee['Month FTE'] != '-'] #removing all the rows without Month FTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit Center Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "profit_center_filename = \"Staffit_KRA.xlsx\"\n",
    "\n",
    "Profit_center = pd.read_excel(data_folder_directory + profit_center_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta,date\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "sdate = date(2020,6,1)   # start date\n",
    "edate = date(2035,6,1)   # end date\n",
    "\n",
    "Dates = pd.DataFrame()\n",
    "Dates['Date'] = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "Dates['Year'] = [Dates['Date'][i].year for i in range(len(Dates))]\n",
    "quarters = Dates['Date'].dt.quarter\n",
    "Dates['QR'] = ['QR'+str(quarters[i]) for i in range(len(Dates))]\n",
    "Dates['Month'] = [Dates['Date'][i].month for i in range(len(Dates))]\n",
    "Dates['Day'] = [Dates['Date'][i].day for i in range(len(Dates))]\n",
    "Dates['Week'] = [Dates['Date'][i].isocalendar()[1] for i in range(len(Dates))]\n",
    "Dates['FY'] = [Dates['Date'][i].year if Dates['Date'][i].month <= 5 else Dates['Date'][i].year + 1 for i in range(len(Dates))]\n",
    "Dates['Month & Year'] = [Dates['Date'][i].strftime(\"%b\") + '-' + str(Dates['Date'][i].year)[-2:] for i in range(len(Dates))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee_levels Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "Employee_levels_filename = \"Table payscale group vs level.xlsx\"\n",
    "\n",
    "#Loading the employee levels source table\n",
    "Employee_levels = pd.read_excel(data_folder_directory + Employee_levels_filename)\n",
    "Employee_levels = Employee_levels.iloc[1:,1:]\n",
    "Employee_levels.columns = Employee_levels.iloc[0]\n",
    "Employee_levels = Employee_levels[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KRA Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "KRA_filename = \"Bestand KRA's (Test).xlsx\"\n",
    "\n",
    "#Loading the KRA source table\n",
    "KRA = pd.read_excel(data_folder_directory + KRA_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Revenue Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "Net_revenue_filename = \"GM analyse Risk Advisory NL (Maart).xlsx\"\n",
    "\n",
    "#Loading the net revenue source table\n",
    "Net_revenue = pd.read_excel(data_folder_directory + Net_revenue_filename,sheet_name=\"QRT004\")\n",
    "col_start = int(Net_revenue.iloc[5][Net_revenue.iloc[5].str.find(\"GM UHC\") == 0].index.to_list()[0].split()[-1])\n",
    "col_end = int(Net_revenue.iloc[5][Net_revenue.iloc[5].str.find(\"Total Chargeable Hours\") == 0].index.to_list()[0].split()[-1])\n",
    "Net_revenue = Net_revenue.iloc[5:,col_start:col_end+1]\n",
    "Net_revenue.columns = Net_revenue.iloc[0]\n",
    "Net_revenue = Net_revenue[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets KRA Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import holidays\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/xhoxha/OneDrive - Deloitte (O365D)/Desktop/PowerBI Report with Python/\"\n",
    "#Input the filenames of the data files below \n",
    "Targets_KRA_filename = \"FY21 hours targets from 6+6.xlsx\"\n",
    "\n",
    "#Loading the Target_KRA source table\n",
    "Targets_KRA = pd.read_excel(data_folder_directory + Targets_KRA_filename,skiprows=2)\n",
    "Targets_KRA = Targets_KRA.iloc[:,1:]\n",
    "Targets_KRA.columns = Targets_KRA.iloc[0]\n",
    "Targets_KRA = Targets_KRA[1:]\n",
    "Targets_KRA = Targets_KRA.reset_index(drop=True)\n",
    "\n",
    "relevant_months = Targets_KRA['Month'].unique()\n",
    "\n",
    "year = datetime.now().year\n",
    "today_month = datetime.now().month\n",
    "today_day = datetime.now().day\n",
    "\n",
    "month_dict = {}\n",
    "WD_actuals_dict = {}\n",
    "\n",
    "for i in range(len(relevant_months)):\n",
    "\n",
    "    month = Targets_KRA['Month'].unique()[i]\n",
    "    month_number = datetime.strptime(month, \"%B\").month\n",
    "    \n",
    "    start = date(year, month_number, 1)\n",
    "    end = date(year, month_number + 1, 1)\n",
    "    \n",
    "    dutch_holidays = holidays.Netherlands()\n",
    "    dutch_holidays = dutch_holidays[start:end]\n",
    "    number_of_workdays = np.busday_count(start,end) #getting number of workdays within this month\n",
    "\n",
    "    workday_holidays = [hday for hday in dutch_holidays if hday.weekday() not in [5,6] and hday != date(year, 4, 2)]\n",
    "    number_of_workday_holidays = len(workday_holidays) #getting number of holidays that are workdays in this month \n",
    "    number_of_workdays = number_of_workdays - number_of_workday_holidays\n",
    "    month_dict[month] = number_of_workdays\n",
    "    \n",
    "    # WD Actuals\n",
    "    if today_month == month_number:\n",
    "        range_actuals = pd.date_range(start, date(year,today_month,today_day), freq='d')\n",
    "        WD_actuals_dict[month] = len([actuals for actuals in range_actuals if actuals.weekday() not in [5,6] and actuals not in workday_holidays]) - 1\n",
    "    elif today_month > month_number:\n",
    "         WD_actuals_dict[month] = number_of_workdays\n",
    "    else:\n",
    "        WD_actuals_dict[month] = 0\n",
    "        \n",
    "        \n",
    "Targets_KRA['WD in this month'] = [month_dict[Targets_KRA['Month'][i]] for i in range(len(Targets_KRA))]\n",
    "Targets_KRA['WD actuals'] = [WD_actuals_dict[Targets_KRA['Month'][i]] for i in range(len(Targets_KRA))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Table :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Creating the Table source table\n",
    "Table = {'Identified':1, 'Contacted':2,'Qualified':3,'Request to Propose':4,'Proposal Submitted':5,'Orals':6,'Verbal Commit':7}\n",
    "Table = pd.DataFrame.from_dict(list(Table.items()))\n",
    "Table.columns = ['Stage','Order']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Making the dates table\n",
    "if datetime.now().month <= 5:\n",
    "    year = datetime.now().year - 1\n",
    "    sdate = date(year, 6, 1)   # fiscal start date\n",
    "    edate = date(year+1, 5, 31)   # fiscal end date\n",
    "    \n",
    "else:\n",
    "    year = datetime.now().year\n",
    "    sdate = date(year, 6, 1)   # fiscal start date\n",
    "    edate = date(year+1, 5, 31)   # fiscal end date\n",
    "    \n",
    "delta = edate - sdate       # as timedelta\n",
    "\n",
    "dates = []\n",
    "for i in range(delta.days + 1):\n",
    "    dates.append(sdate + timedelta(days=i))\n",
    "\n",
    "Dates = pd.DataFrame()\n",
    "Dates['Dates'] = dates\n",
    "Dates['Month & Year'] = [date.strftime(\"%b\") + '-' + date.strftime(\"%y\") for date in Dates['Dates']]\n",
    "month_mapping = {'Jun':1, 'Jul':2, 'Aug':3, 'Sep':4, 'Oct':5, 'Nov':6, 'Dec':7, 'Jan':8, 'Feb':9, 'Mar':10, 'Apr':11, 'May':12}\n",
    "Dates['FiscalMIndex'] = [month_mapping[Dates['Month & Year'][i].split('-')[0]] for i in range(len(Dates))]\n",
    "Dates['Month'] = [Dates['Dates'][i].strftime(\"%B\") for i in range(len(Dates))]\n",
    "Dates['Month short'] = [Dates['Dates'][i].strftime(\"%b\") for i in range(len(Dates))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "#Making the Month Order table\n",
    "Month_order = pd.DataFrame()\n",
    "if datetime.now().month <= 5:\n",
    "    last_year = datetime.now().year - 1\n",
    "    sdate = date(last_year, 6, 1)   # fiscal start date\n",
    "    edate = date(last_year+1, 5, 31)   # fiscal end date\n",
    "else:\n",
    "    current_year = datetime.now().year\n",
    "    sdate = date(current_year, 6, 1)   # fiscal start date\n",
    "    edate = date(current_year+1, 5, 31)   # fiscal end date\n",
    "        \n",
    "month_list = pd.date_range(datetime.now(),edate).strftime(\"%B\").unique().tolist()\n",
    "month_idx = [strptime(month,'%B').tm_mon for month in month_list]\n",
    "Month_order['Month'] = month_list\n",
    "Month_order['Order'] = month_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAFFIT Report Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from os import listdir\n",
    "\n",
    "def get_date(file_name):\n",
    "    \"\"\"\n",
    "    Function to get the dates from the Staffing Report filenames for sorting later.\n",
    "    \"\"\"\n",
    "    date_str = file_name.split(\"-\")[1].split(\".\")[0].strip()\n",
    "    date = datetime.strptime(date_str, '%B %d_%Y')\n",
    "    \n",
    "    return date\n",
    "\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "list_of_files = listdir(data_folder_directory)\n",
    "\n",
    "staffing_report_files = [f for f in list_of_files if \"Staffing Report\" in f]\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for i in staffing_report_files:\n",
    "    dates_dict[i] = get_date(i)\n",
    "\n",
    "sorted_staffing_reports = sorted(dates_dict.items(), key = lambda item: item[1])\n",
    "new_staffing_report = staffing_report_files[-1]\n",
    "\n",
    "#Creating the table for Staffit report file for planning\n",
    "df = pd.read_excel(data_folder_directory + new_staffing_report,skiprows=4)\n",
    "df = df.iloc[:,:-1] #We don't want the last column because they are totals\n",
    "\n",
    "practice_idx = df.columns.get_loc(\"Practice\")\n",
    "temp = df.iloc[:,practice_idx+1:]\n",
    "\n",
    "if datetime.now().month <= 5:\n",
    "    fiscal_end_year = datetime.now().year\n",
    "else:\n",
    "    fiscal_end_year = datetime.now().year + 1\n",
    "\n",
    "end_fiscal = datetime(fiscal_end_year, 6, 1)\n",
    "\n",
    "#Getting a list of irrelevant columns that need to be dropped from the dataset, i.e. columns that have dates that are outside of range between the current month and end of current fiscal year\n",
    "\n",
    "columns_to_drop = [temp.columns[i] for i in range(len(temp.columns)) if not ((datetime.strptime(temp.columns[i][0:11], '%d-%b-%Y') < end_fiscal) and (int(temp.columns[i][-2:]) >= date.today().isocalendar()[1]))]\n",
    "df = df.drop(columns_to_drop,axis=1).iloc[:-1,:]\n",
    "\n",
    "practice_idx = df.columns.get_loc(\"Practice\")\n",
    "temp = df.iloc[:,practice_idx+1:]\n",
    "df[temp.columns] = df[temp.columns].fillna(value=0)\n",
    "\n",
    "for col in temp.columns:\n",
    "    work_week = int(col[-2:])\n",
    "    work_year = int(col[-9:-5])\n",
    "    #Check if the starting date and the ending date of certain workweek are in different months. And if so, we need to split the hours.\n",
    "    if date.fromisocalendar(work_year, work_week, 1).month != date.fromisocalendar(work_year, work_week, 5).month:\n",
    "        days_diff = (pd.Period(col[0:11],freq='M').end_time.date() - date.fromisocalendar(work_year, work_week, 1)).days\n",
    "        \n",
    "        col_before = df[col].copy()\n",
    "        df[col] *= (1 - days_diff / 5)\n",
    "        col_after = df[col].copy()\n",
    "        differences = [before - after for before, after in zip(col_before, col_after)]\n",
    "        \n",
    "        #Taking care of edge cases where the last month of our dataset has two different months, in that case we do not need to split.\n",
    "        try:\n",
    "            idx = df.columns.get_loc(col)\n",
    "            next_col = df.columns[idx + 1]\n",
    "            df[next_col] = [x + y for x,y in zip(df[next_col],differences)]\n",
    "    \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "#Unpivot the dataframe to be able to visualize it\n",
    "STAFFIT_report = pd.melt(df, id_vars=['Practitioner Name','Local Client ID','Client Description','Request Name', 'Booking Type', 'Cost Centre Desc',\n",
    "       'Member Firm Emp ID', 'Cost Centre', 'Capability Desc', 'Role Number',\n",
    "       'Resource Requester', 'Engagement Manager', 'Business Desc Demand',\n",
    "       'Role Name', 'Business Line', 'Assignment Type', 'Allocation Type',\n",
    "       'Assignment Start Date', 'Assignment End Date', 'Engagement Code',\n",
    "       'Engagement Description', 'Engagement Industry', 'Resource Manager',\n",
    "       'Staffing Region', 'Federal Account', 'Global Level', 'Local Level','Request Number','Office','Practice'], var_name='Workweek', value_name='Planning Hours')\n",
    "STAFFIT_report['Month'] = [datetime.strptime(STAFFIT_report['Workweek'][i][0:11], '%d-%b-%Y').strftime(\"%B\") for i in range(len(STAFFIT_report))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Revenue Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import collections\n",
    "\n",
    "#Input the directory of the folder that contains the data files below\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "#Input the filenames of the data files below \n",
    "jupiter_pipeline_filename = \"Jupiter pipeline 20210317.xlsx\"\n",
    "\n",
    "#Creating the table for Staffit report file for planning\n",
    "Jupiter_pipeline = pd.read_excel(data_folder_directory + jupiter_pipeline_filename)\n",
    "Jupiter_pipeline = Jupiter_pipeline[Jupiter_pipeline['Stage'].isin(['Orals','Contacted','Identified','Proposal Submitted', 'Qualified', 'Request to Propose', 'Verbal Commit'])]\n",
    "Jupiter_pipeline = Jupiter_pipeline[Jupiter_pipeline['Engagement Duration (Days)'].notnull()]\n",
    "Jupiter_pipeline = Jupiter_pipeline.reset_index(drop=True)\n",
    "\n",
    "#First, we want to get all the months that are relevant within our dataset, this is stored in the counter dict which will be used later to track the number of days in each month.\n",
    "result = []\n",
    "for i in range(len(Jupiter_pipeline)):\n",
    "    result += pd.date_range(Jupiter_pipeline['Project Start Date'][i],Jupiter_pipeline['Project End Date'][i], \n",
    "                  freq='MS').strftime(\"%B-%y\").tolist()\n",
    "relevent_months = list(set(result))\n",
    "counter = dict.fromkeys(relevent_months, [])\n",
    "\n",
    "def number_of_days(start_date, end_date):\n",
    "    \"\"\"\n",
    "    This function is used to get the dictionary with key being the month and value being the number of days that are in that month.\n",
    "    The function takes in the starting date and ending date and returns a dictionary which shows the number of days for each month within that time range.\n",
    "    \"\"\"\n",
    "    month_dict = collections.defaultdict(int)\n",
    "    date = start_date\n",
    "    \n",
    "    while date <= end_date:\n",
    "        key = '{}-{}'.format(date.strftime('%B'),str(date.year)[-2:])\n",
    "\n",
    "        month_dict[key] += 1\n",
    "        date += timedelta(days=1)\n",
    "\n",
    "    return month_dict\n",
    "\n",
    "for i in range(len(Jupiter_pipeline)):\n",
    "    start_date = Jupiter_pipeline['Project Start Date'][i]\n",
    "    end_date = Jupiter_pipeline['Project End Date'][i]\n",
    "    #Calling the number_of_days function to get the number of days for relevant months for each row in the dataset\n",
    "    relevant_months_dict = number_of_days(start_date, end_date)\n",
    "    \n",
    "    for k,v in counter.items():\n",
    "        if k in relevant_months_dict.keys():\n",
    "            counter[k] = counter[k] + [relevant_months_dict[k]]\n",
    "        else:\n",
    "            counter[k] = counter[k] + [0]\n",
    "            \n",
    "temp = pd.DataFrame.from_dict(counter)\n",
    "for i in range(len(temp)):\n",
    "    temp.iloc[i] = temp.iloc[i] * (Jupiter_pipeline['Weighted Split Amount (converted)'][i] / Jupiter_pipeline['Engagement Duration (Days)'][i])\n",
    "    \n",
    "relevant_df = Jupiter_pipeline[['Opportunity Leader', 'Split Leader', 'Industry', 'Sector',\n",
    "       'Account Name', 'Opportunity ID', 'Opportunity Name',\n",
    "       'Opportunity Split: Opportunity Split ID', 'Stage','Client Service Level 1', 'Client Service L1', 'Client Service Level 2',\n",
    "       'Client Service Level 3', 'Client Service Level 4', 'Function Level 1']]\n",
    "\n",
    "#Merging the two dataframes together to get the final dataframe \n",
    "final_df = pd.concat([relevant_df, temp], axis=1)\n",
    "#Unpivot the dataframe so that we can visualize it in PowerBI\n",
    "final_df = pd.melt(final_df, id_vars=['Opportunity Leader', 'Split Leader', 'Industry', 'Sector',\n",
    "       'Account Name', 'Opportunity ID', 'Opportunity Name',\n",
    "       'Opportunity Split: Opportunity Split ID', 'Stage','Client Service Level 1', 'Client Service L1', 'Client Service Level 2',\n",
    "       'Client Service Level 3', 'Client Service Level 4', 'Function Level 1'], var_name='Month', value_name='Expected Revenue')\n",
    "\n",
    "#Creating the MIndex column so that we can sort the month column in PowerBI\n",
    "ranked_months = sorted(final_df['Month'], key = lambda x: (int(x.split('-')[1]), datetime.strptime(x.split('-')[0], \"%B\").month))\n",
    "ranked_months = list(dict.fromkeys(ranked_months))\n",
    "\n",
    "MIndex_dict = {}\n",
    "acc = 1\n",
    "for i in ranked_months:\n",
    "    MIndex_dict[i] = acc\n",
    "    acc += 1\n",
    "    \n",
    "final_df['Month_MIndex'] = [MIndex_dict[final_df['Month'][i]] for i in range(len(final_df))]\n",
    "final_df['Dates'] = [datetime.strptime(final_df['Month'][i], \"%B-%y\").strftime(\"%m-%d-%Y\") for i in range(len(final_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EGM Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "\n",
    "def get_date(file_name):\n",
    "    \"\"\"\n",
    "    Function to get the dates from the EGM filenames for sorting later.\n",
    "    \"\"\"\n",
    "    date_str = file_name.split(\"-\")[-1][3:11]\n",
    "    date = datetime.strptime(date_str, '%d%m%Y')\n",
    "    \n",
    "    return date\n",
    "\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "list_of_files = listdir(data_folder_directory)\n",
    "\n",
    "EGM_MTD_files = [f for f in list_of_files if \"GM analyse QRT004 - UHC Profitability-MTD\" in f]\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for i in EGM_MTD_files:\n",
    "    dates_dict[i] = get_date(i)\n",
    "\n",
    "sorted_EGM_MTD_files = sorted(dates_dict.items(), key = lambda item: item[1])\n",
    "new_EGM_MTD = sorted_EGM_MTD_files[-1][0]\n",
    "\n",
    "EGM_YTD_files = [f for f in list_of_files if \"GM analyse QRT004 - UHC Profitability-YTD\" in f]\n",
    "\n",
    "#Loading in the EGM_MTD table\n",
    "EGM_MTD = pd.read_excel(data_folder_directory + new_EGM_MTD,sheet_name='QRT004')\n",
    "col_start = np.where(EGM_MTD.iloc[5].str.find(\"GM UHC\") == 0)[0][0]\n",
    "col_end = np.where(EGM_MTD.iloc[5].str.find(\"Total Chargeable Hours\") == 0)[0][0]\n",
    "EGM_MTD = EGM_MTD.iloc[5:,col_start:col_end+1]\n",
    "EGM_MTD.columns = EGM_MTD.iloc[0]\n",
    "EGM_MTD = EGM_MTD[1:]\n",
    "month_name = sorted_EGM_MTD_files[-1][1].strftime(\"%B\")\n",
    "EGM_MTD['Month'] = [month_name for i in range(len(EGM_MTD))]\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for i in EGM_YTD_files:\n",
    "    dates_dict[i] = get_date(i)\n",
    "\n",
    "sorted_EGM_YTD_files = sorted(dates_dict.items(), key = lambda item: item[1])\n",
    "new_EGM_YTD = sorted_EGM_YTD_files[-1][0]\n",
    "\n",
    "#Loading in the EGM_YTD table\n",
    "EGM_YTD = pd.read_excel(data_folder_directory + new_EGM_YTD,sheet_name='QRT004')\n",
    "col_start = np.where(EGM_YTD.iloc[5].str.find(\"GM UHC\") == 0)[0][0]\n",
    "col_end = np.where(EGM_YTD.iloc[5].str.find(\"Total Chargeable Hours\") == 0)[0][0]\n",
    "EGM_YTD = EGM_YTD.iloc[5:,col_start:col_end+1]\n",
    "EGM_YTD.columns = EGM_YTD.iloc[0]\n",
    "EGM_YTD = EGM_YTD[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing & Parked Hours Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "\n",
    "def get_date(file_name):\n",
    "    \"\"\"\n",
    "    Function to get the dates from the missing hours and parked hours filenames for sorting later.\n",
    "    \"\"\"\n",
    "    return datetime.strptime(file_name.split()[1], '%d-%m-%Y')\n",
    "\n",
    "def load_missing_hours(filename):\n",
    "    \"\"\"\n",
    "    Function to perform loading and preprocessing of the missing hours files. \n",
    "    \"\"\"\n",
    "    Missing_hours = pd.read_excel(data_folder_directory + filename,sheet_name=\"Data\")\n",
    "    Month = [date.strftime(\"%b\") for date in Missing_hours['To Date']]\n",
    "    Year = [str(date.year)[-2:] for date in Missing_hours['To Date']]\n",
    "    Missing_hours['Month & Year'] = list(map('-'.join, zip(Month, Year)))\n",
    "    \n",
    "    ranked_months = sorted(Missing_hours['Month & Year'], key = lambda x: (int(x.split('-')[1]), datetime.strptime(x.split('-')[0], \"%b\").month))\n",
    "\n",
    "    #Below creates a dictionary with values being 0 and distinct keys from ranked_months\n",
    "    ranked_dict = dict.fromkeys(ranked_months, 0)\n",
    "    \n",
    "    #Create a dictionary to keep track of the MIndex\n",
    "    acc = 1\n",
    "    for k,v in ranked_dict.items():\n",
    "        ranked_dict[k] += acc\n",
    "        acc += 1 \n",
    "\n",
    "    Missing_hours['Months_MIndex'] = [ranked_dict[Missing_hours['Month & Year'][i]] for i in range(len(Missing_hours))]\n",
    "    \n",
    "    return Missing_hours\n",
    "\n",
    "def load_parked_hours(filename):\n",
    "    \"\"\"\n",
    "    Function to perform loading and preprocessing of the parked hours files. \n",
    "    \"\"\"\n",
    "    Parked_hours = pd.read_excel(data_folder_directory + filename,sheet_name=\"Data incl. comments on hours\")\n",
    "    Parked_hours['Work Date'] = pd.to_datetime(Parked_hours['Work Date'],format=\"%d-%m-%Y\") #Parked hours using Dutch format\n",
    "    Month = [date.strftime(\"%b\") for date in Parked_hours['Work Date']]\n",
    "    Year = [str(date.year)[-2:] for date in Parked_hours['Work Date']]\n",
    "    Parked_hours['Month & Year'] = list(map('-'.join, zip(Month, Year)))\n",
    "    \n",
    "    ranked_months = sorted(Parked_hours['Month & Year'], key = lambda x: (int(x.split('-')[1]), datetime.strptime(x.split('-')[0], \"%b\").month))\n",
    "\n",
    "    #Below creates a dictionary with values being 0 and distinct keys from ranked_months\n",
    "    ranked_dict = dict.fromkeys(ranked_months, 0)\n",
    "    \n",
    "    #Create a dictionary to keep track of the MIndex\n",
    "    acc = 1\n",
    "    for k,v in ranked_dict.items():\n",
    "        ranked_dict[k] += acc\n",
    "        acc += 1 \n",
    "\n",
    "    Parked_hours['Months_MIndex'] = [ranked_dict[Parked_hours['Month & Year'][i]] for i in range(len(Parked_hours))]\n",
    "    \n",
    "    return Parked_hours\n",
    "\n",
    "data_folder_directory = \"C:/Users/jimmlin/OneDrive - Deloitte (O365D)/Desktop/Jupiter Report/\"\n",
    "list_of_files = listdir(data_folder_directory)\n",
    "\n",
    "missing_hours_files = [f for f in list_of_files if \"Missings\" in f]\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for i in missing_hours_files:\n",
    "    dates_dict[i] = get_date(i)\n",
    "\n",
    "sorted_missing_hours = sorted(dates_dict.items(), key = lambda item: item[1])\n",
    "\n",
    "new_missing_hours = sorted_missing_hours[-1][0]\n",
    "old_missing_hours = sorted_missing_hours[-2][0]\n",
    "\n",
    "New_missing_hours = load_missing_hours(new_missing_hours)\n",
    "Old_missing_hours = load_missing_hours(old_missing_hours)\n",
    "\n",
    "parked_hours_files = [f for f in list_of_files if \"Parked\" in f]\n",
    "\n",
    "dates_dict = {}\n",
    "\n",
    "for i in parked_hours_files:\n",
    "    dates_dict[i] = get_date(i)\n",
    "\n",
    "sorted_parked_hours = sorted(dates_dict.items(), key = lambda item: item[1])\n",
    "\n",
    "new_parked_hours = sorted_parked_hours[-1][0]\n",
    "old_parked_hours = sorted_parked_hours[-2][0]\n",
    "\n",
    "New_parked_hours = load_parked_hours(new_parked_hours)\n",
    "Old_parked_hours = load_parked_hours(old_parked_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
